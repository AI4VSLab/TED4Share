{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Path/To/Your/Project'\n",
    "csv_path = 'path to test csv/test.csv'\n",
    "ckpt_path = 'path to ckpt'\n",
    "save_path = 'path to save images'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from PIL import Image, UnidentifiedImageError, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradcam function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def visualize_grad_cam(model, target_layers, img_path='', class_target=1, save_path=None, show_image=True,device = 'cpu'):\n",
    "    '''\n",
    "    Optimized version to reduce GPU memory usage. Ensure to pass model and target_layers directly if they do not change.\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Function to preprocess and read the image\n",
    "    def process_image(img_path):\n",
    "        def read_img(p):\n",
    "            image = read_image(p)\n",
    "            # if 4 channels need to convert colour space\n",
    "            if image.shape[0] != 3:\n",
    "                image = cv2.imread(p, cv2.IMREAD_UNCHANGED)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGBA2BGR  ) \n",
    "                image = torch.tensor(image).permute((2,0,1))\n",
    "            return image\n",
    "        image = read_img(img_path).float() / 255\n",
    "        image_shape = image.shape\n",
    "        image = image.unsqueeze(0)\n",
    "        image = torch.nn.functional.interpolate(image, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return image, image_shape #.to(device)\n",
    "    \n",
    "    def process_image_direct(image_path):\n",
    "        # this is their method, the other is what i used to do \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_shape = (3, image.size[1], image.size[0])\n",
    "        image = image.resize((224, 224))\n",
    "        image = test_transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "            \n",
    "        return image, image_shape\n",
    "\n",
    "    # Load and process the image\n",
    "    #with torch.no_grad():  # Disable gradient computation\n",
    "    input_tensor, image_shape = process_image_direct(img_path)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    targets = [ClassifierOutputTarget(class_target)]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]  # Get first image CAM\n",
    "\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.float32(img) / 255\n",
    "\n",
    "    \n",
    "\n",
    "    # Overlay the CAM on the image\n",
    "    visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    visualization = cv2.resize(visualization, (image_shape[2],image_shape[1]))\n",
    "\n",
    "    # Save and/or show the visualization\n",
    "    if save_path:\n",
    "        saved_path = f'{save_path}/{img_path.split(\"/\")[-1]}'\n",
    "        plt.imsave(saved_path, visualization)\n",
    "        plt.close()\n",
    "\n",
    "    if show_image:\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Cleanup\n",
    "    del input_tensor, grayscale_cam  # Remove tensors from memory\n",
    "    torch.cuda.empty_cache()  # Optionally clear memory cache if needed\n",
    "\n",
    "    if save_path: return visualization, saved_path\n",
    "\n",
    "    return visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup: load ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.classification import ClassificationNet\n",
    "from util.get_models import get_baseline_model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "classes = {\"TED_1\": 1, \"CONT_\": 0}\n",
    "# load df \n",
    "df_test = pd.read_csv(csv_path)\n",
    "\n",
    "# load model\n",
    "encoder = get_baseline_model(pretrained=True, model_architecture= 'resnet50')\n",
    "model = ClassificationNet( # make sure to define the model architecture and parameters correctly\n",
    "    feature_dim= 2048,\n",
    "    encoder=encoder,\n",
    "    classes=classes,\n",
    "    lr=3e-5,              \n",
    "    loss_type=\"focal\"    \n",
    ")\n",
    "\n",
    "state_dict = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/CenteredData/TED Federated Learning Project/ted_manual_preprocessing/TED_1081.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.directory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this image is class 0\n",
    "img_path = '../TED4Share/demo_images/100224.jpg.png'\n",
    "visualization  = visualize_grad_cam(\n",
    "                                    model = model.encoder,\n",
    "                                    target_layers = [model.encoder[0].layer4[-1]],\n",
    "                                    class_target = 0,\n",
    "                                    img_path = img_path, \n",
    "                                    save_path=None, show_image=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    img_path = row['directory']\n",
    "    class_target = row['label']\n",
    "    print(img_path)\n",
    "    visualization  = visualize_grad_cam(\n",
    "                                        model = model.encoder,\n",
    "                                        target_layers = [model.encoder[0].layer4[-1]],\n",
    "                                        class_target = class_target,\n",
    "                                        img_path = img_path, \n",
    "                                        save_path=save_path, show_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_new_pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
